# 手绘图识别与修复版 Workflow（文本语境现场处置培训系统）

## 1. 手绘图文字识别与修复

### 图1（总览）
- 原意：`基于大模型的AI案件处置培训系统`（LLM-Based Case Handling AI System）
- 技术栈：Flutter 3.x（修正：手写中“3.0”表述过窄，统一为 3.x）
- 平台：Windows / Linux / Web(Chrome) / Android / iOS / macOS
- 核心功能：
  1. 多级权限（后期）
  2. 文本语境下案件处置测试（核心）
  3. 处置措施打分系统（核心）
  4. 提示词工程设计（模型逻辑）

### 图2（案件处置测试模块）
- 方案一：纯人工设计案例 → 结构化模板 → 导入题库
- 方案二：人工模板 + AI案例衍生 → 规范化后导入题库
- 公共流：
  - 案例模板数据库（Case Template DB）
  - 案例题库数据库（Case Question Bank DB）
  - 处置端（打分点）Embedding 数据
- 识别修复：
  - “格式化决策结构化数据”应为“格式化决策结构数据”
  - “嵌入及LLM”语义不清，修复为“由同一 embedding 模型生成向量并写入向量包”

### 图3（处置措施打分模块）
- 输入：用户文本作答 + 题目标准流程
- 过程：LLM/规则提取处置要点 → 计算要点评分 embedding 相似度 → 打分
- 三维评分（图中“评分依据”）：
  1. 处置要点完整度
  2. 与标准处置流程相似度
  3. 处置逻辑顺序与程序合规相似度
- 识别修复：
  - “Embedding语义相等”修复为“Embedding语义相似”
  - “把考到了他一颗...”示例语句不通，修复为“词面不同但语义等价可获得高相似度”

## 2. 完整化后的系统 Workflow

1. **Server-题库设计**：人工编辑模板题；可选择规则扩展题；统一入 SQLite。
2. **Server-向量构建**：对题目 stem/title 生成 embedding，打包为 `.pak`。
3. **Client-发题作答**：按 question_id 拉题，用户提交文本答案。
4. **Client-RAG 检索**：query=题干+作答，检索题库 topK 作为评分语境补充。
5. **Client-打分引擎**：
   - 关键词命中率（显性）
   - 语义相似度（隐性）
   - 分层加权（analysis_level）
6. **结果输出**：总分、分点得分、改进建议，写回 training_attempt。

## 3. 对原方案打分（100分制）

- 功能性：**86**（核心模块齐全，但缺少数据契约）
- 可落地性：**82**（可实现，但原稿未明确失败回退与版本约束）
- 逻辑正确性：**88**（流程主线正确，细节需补充）

## 4. 优化与重设计要点

- 明确“软硬编码分离”：模板与评分点全部 YAML 外置。
- 增加 `.pak` 二进制向量包规范：magic + payload length + JSON payload。
- 统一评分接口：`关键词 x 语义 + 分层权重`，避免单一规则误判。
- 补齐审计闭环：`analyze/test/命令演练` 全通过后才能发布。
